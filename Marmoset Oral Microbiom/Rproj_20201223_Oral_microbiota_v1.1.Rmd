---
title: "20201230_Oral_microbiota"
author: "whzemuch"
date: "12/30/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### library
```{r chunk1, warning=FALSE, message=FALSE, error=FALSE }
library(dada2)
library(phyloseq)
library(data.table)
library(tidyverse)
library(patchwork)
library(export)

```


### Prepair data for analysis
```{r chunk2, warning=FALSE, message=FALSE, error=FALSE}
# get the file path
miseq_path <- file.path("data", "miseq")
filt_path <- file.path("data", "filtered")

# get the list of R1 and R2
fns <- sort(list.files(miseq_path, full.names = TRUE))
fnFs <- fns[grepl("R1", fns)]
fnRs <- fns[grepl("R2", fns)]

samples_name <- paste0("m", str_extract(basename(fnFs), "^\\d{2,}"))



sample_info <- read_csv("./data/sample_info.csv")
sample_df <-  sample_info %>% 
  select(sample, age, gender, group) %>% 
  column_to_rownames(var = "sample")

save(sample_df, file = "sample_df.Rdata")

```


### Inspect read quality profiles
```{r chunk3, warning=FALSE, message=FALSE, error=FALSE}

# check the sequencing quality
plotQualityProfile(fnFs[8]) + ggtitle("Fwd") + geom_vline(xintercept = 240, color="blue")
plotQualityProfile(fnRs[9]) + ggtitle("Rev") + geom_vline(xintercept = 180, color="red")


```


### Filter and trim
```{r chunk4, warning=FALSE, message=FALSE, error=FALSE}


# Place filtered files in filtered/ subdirectory

if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(filt_path, paste0(samples_name, "_R1_filt_fastq.gz"))
filtRs <- file.path(filt_path, paste0(samples_name, "_R2_filt_fastq.gz"))

names(filtFs) <- samples_name
names(filtRs) <- samples_name



out <- filterAndTrim(
              fnFs, filtFs, fnRs, filtRs, 
              trimLeft = 20, truncLen=c(240,180),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=FALSE) # On Windows set multithread=FALSE
head(out)

```


### Dereplicated
```{r chunk4, warning=FALSE, message=FALSE, error=FALSE}
derepFs <- derepFastq(filtFs)
derepRs <- derepFastq(filtRs)

names(derepFs) <- samples_name
names(derepRs) <- samples_name

```


### Learn error rates
```{r chunk5, warning=FALSE, message=FALSE, error=FALSE}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=FALSE)

plotErrors(errF, nominalQ = TRUE) + ggtitle("Fwd")
plotErrors(errR, nominalQ = TRUE) + ggtitle("Rev")

save(errF, errR, file = "errF_R.rdata")

```


### Sample Inference
```{r chunk6, warning=FALSE, message=FALSE, error=FALSE }

dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)


```


### Merge paired reads
```{r chunk7, warning=FALSE, message=FALSE, error=FALSE}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE)


head(mergers[[1]])

save(derepFs, derepRs, dadaFs, dadaRs, mergers, file = "dada_mergers.Rdata")

```


### Construct sequence table
```{r chunk8, warning=FALSE, message=FALSE, error=FALSE}


seqtab <- makeSequenceTable(mergers)
dim(seqtab)

# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))

save(seqtab, file = "seqtab.Rdata")
```


### Remove chimeras
```{r chunk9, warning=FALSE, message=FALSE, error=FALSE }

seqtab.nochim <- removeBimeraDenovo(seqtab, multithread=TRUE)

dim(seqtab.nochim)

save(seqtab.nochim, file = "seqtab.nochim.Rdata")

```


### Reads processing summary table
```{r chunk10, warning=FALSE, message=FALSE, error=FALSE}

getN <- function(x) sum(getUniques(x))


summary_tab <- tibble(
                          row.names=samples_name, 
                          dada2_input=out[, 1],
                          filtered=out[, 2], 
                          dada_f=sapply(dadaFs, getN),
                          dada_r=sapply(dadaRs, getN), 
                          merged=sapply(mergers, getN),
                          chimera_seqs=rowSums(seqtab) - rowSums(seqtab.nochim),
                          unique_seqs = rowSums(seqtab.nochim > 0),
                          chimera_free_seqs=rowSums(seqtab.nochim),
                          final_perc_reads_retained=round(rowSums(seqtab.nochim)/out[,1]*100, 1)
               )

summary_tab
save(summary_tab, file = "summary_tbl.Rdata")

```


### Assign taxonomy
```{r chunk11, warning=FALSE, message=FALSE, error=FALSE}
names(seqtab)

ref_dataset <- "./data/silva_nr_v132_train_set.fa.gz"

taxa <- assignTaxonomy(seqtab.nochim, ref_dataset, multithread = TRUE)
taxa <- addSpecies(taxa,"./data/silva_species_assignment_v132.fa.gz")

taxa %>% as_tibble()

save(taxa, file = "taxa_tbl.Rdata")

```




